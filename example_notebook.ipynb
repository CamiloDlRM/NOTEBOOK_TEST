{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps Example Notebook - Iris Classifier\n",
    "\n",
    "This notebook demonstrates the required cell tags for the MLOps platform.\n",
    "Each code cell has a `tags` entry in its metadata that the platform uses\n",
    "to identify pipeline phases.\n",
    "\n",
    "**Required tags:** `mlops:config`, `mlops:preprocessing`, `mlops:training`, `mlops:export`\n",
    "\n",
    "**Optional tags:** `mlops:data`, `mlops:evaluation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Papermill injected parameters (do not edit this cell manually)\n",
    "# These are overwritten at runtime by the pipeline.\n",
    "MODEL_OUTPUT_PATH = \"./model.joblib\"\n",
    "PIPELINE_ID = \"local-dev\"\n",
    "MLFLOW_TRACKING_URI = \"http://localhost:5000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "mlops:config"
    ]
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# mlops:config - Model metadata\n",
    "# ============================================================\n",
    "# Adapt MODEL_NAME and VERSION for your project.\n",
    "# The platform reads these values to register the model.\n",
    "\n",
    "MODEL_NAME = \"iris-classifier\"\n",
    "VERSION = \"1\"\n",
    "\n",
    "print(f\"Model: {MODEL_NAME} v{VERSION}\")\n",
    "print(f\"Pipeline ID: {PIPELINE_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "mlops:data"
    ]
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# mlops:data - Data loading\n",
    "# ============================================================\n",
    "# Replace this with your own data loading logic.\n",
    "# The platform does not require a specific data source.\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = pd.Series(iris.target, name=\"target\")\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Classes: {list(iris.target_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "mlops:preprocessing"
    ]
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# mlops:preprocessing - Data preparation\n",
    "# ============================================================\n",
    "# Add feature engineering, scaling, splitting, etc.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Train: {X_train_scaled.shape}, Test: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "mlops:training"
    ]
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# mlops:training - Model training\n",
    "# ============================================================\n",
    "# Replace RandomForestClassifier with your own model.\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "mlops:evaluation"
    ]
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# mlops:evaluation - Metrics and logging\n",
    "# ============================================================\n",
    "# Log metrics to MLflow. The platform reads 'accuracy' for\n",
    "# auto-deployment decisions.\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=list(iris.target_names)))\n",
    "print(f\"Accuracy: {score:.4f}\")\n",
    "\n",
    "# Log to MLflow (the pipeline wraps execution in an MLflow run)\n",
    "mlflow.log_metric(\"accuracy\", score)\n",
    "mlflow.log_metric(\"n_estimators\", 100)\n",
    "mlflow.log_metric(\"max_depth\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "mlops:export"
    ]
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# mlops:export - Save model artifact\n",
    "# ============================================================\n",
    "# Save the trained model to MODEL_OUTPUT_PATH.\n",
    "# The platform picks up this file and registers it in MLflow.\n",
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(model, MODEL_OUTPUT_PATH)\n",
    "print(f\"Model saved to {MODEL_OUTPUT_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
